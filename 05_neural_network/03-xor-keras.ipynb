{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclusive OR with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is required, else the results of the model training will differ vastly.\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[0, 0],\n",
    "                    [0, 1],\n",
    "                    [1, 0],\n",
    "                    [1, 1]])\n",
    "\n",
    "y_train = np.array([[0],\n",
    "                    [1],\n",
    "                    [1],\n",
    "                    [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "# The fully connected hidden layer will have 100 neurons.\n",
    "    num_neurons = 10\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(num_neurons, activation='relu', input_dim=2),\n",
    "        # The output layer has one neuron to output a single binary classification value (0 or 1).\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    sgd = SGD(0.1)\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Alternatively, we can use add each layer independently.\n",
    "# model.add(Dense(num_neurons, activation='relu', input_dim=2))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "# Overview of the network parameter and number of weights at each stage.\n",
    "# 10 neurons, each with two weights (one for each value in the input vector), \n",
    "# and one weight for the bias gives you 30 weights to learn.\n",
    "# The output layer has a weight for each of the 10 neurons in the first layer \n",
    "# and one bias weight for a total of 11 in that layer.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       ],\n",
       "       [0.46391153],\n",
       "       [0.49188069],\n",
       "       [0.4025334 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1221 14:49:22.680227 4554309056 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 21ms/sample - loss: 0.6714 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.6677 - accuracy: 0.2500\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 488us/sample - loss: 0.6642 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 449us/sample - loss: 0.6608 - accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.6575 - accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 955us/sample - loss: 0.6544 - accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 493us/sample - loss: 0.6513 - accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.6483 - accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 684us/sample - loss: 0.6455 - accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.6426 - accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.6399 - accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6372 - accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.6349 - accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 12ms/sample - loss: 0.6331 - accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6313 - accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.6294 - accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.6276 - accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.6257 - accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 541us/sample - loss: 0.6239 - accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.6220 - accuracy: 0.7500\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 578us/sample - loss: 0.6206 - accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 500us/sample - loss: 0.6188 - accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 490us/sample - loss: 0.6174 - accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6160 - accuracy: 0.7500\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6142 - accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6131 - accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.6110 - accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 996us/sample - loss: 0.6095 - accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 510us/sample - loss: 0.6082 - accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 899us/sample - loss: 0.6069 - accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.6054 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6036 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 495us/sample - loss: 0.6026 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 521us/sample - loss: 0.6003 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 504us/sample - loss: 0.5997 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 489us/sample - loss: 0.5972 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.5963 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5943 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 415us/sample - loss: 0.5927 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 767us/sample - loss: 0.5913 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 813us/sample - loss: 0.5891 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 673us/sample - loss: 0.5875 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 715us/sample - loss: 0.5862 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 654us/sample - loss: 0.5844 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.5824 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 879us/sample - loss: 0.5812 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5787 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 541us/sample - loss: 0.5777 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 687us/sample - loss: 0.5754 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.5737 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5721 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 344us/sample - loss: 0.5695 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 637us/sample - loss: 0.5688 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 667us/sample - loss: 0.5661 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 405us/sample - loss: 0.5649 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 332us/sample - loss: 0.5628 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 349us/sample - loss: 0.5606 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 548us/sample - loss: 0.5595 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 756us/sample - loss: 0.5565 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 612us/sample - loss: 0.5552 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 890us/sample - loss: 0.5531 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5518 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 488us/sample - loss: 0.5488 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 337us/sample - loss: 0.5471 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 317us/sample - loss: 0.5453 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 479us/sample - loss: 0.5435 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 514us/sample - loss: 0.5418 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 711us/sample - loss: 0.5388 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5373 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 675us/sample - loss: 0.5354 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 263us/sample - loss: 0.5337 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 540us/sample - loss: 0.5308 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 539us/sample - loss: 0.5287 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5268 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 619us/sample - loss: 0.5251 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 695us/sample - loss: 0.5232 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 378us/sample - loss: 0.5202 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 777us/sample - loss: 0.5181 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 687us/sample - loss: 0.5163 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 325us/sample - loss: 0.5141 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 585us/sample - loss: 0.5125 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 347us/sample - loss: 0.5093 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 811us/sample - loss: 0.5083 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 768us/sample - loss: 0.5055 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 560us/sample - loss: 0.5028 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 370us/sample - loss: 0.5016 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 328us/sample - loss: 0.4982 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 295us/sample - loss: 0.4969 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 365us/sample - loss: 0.4943 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 301us/sample - loss: 0.4912 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 469us/sample - loss: 0.4897 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 462us/sample - loss: 0.4870 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 337us/sample - loss: 0.4854 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 538us/sample - loss: 0.4818 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 372us/sample - loss: 0.4808 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 292us/sample - loss: 0.4782 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 727us/sample - loss: 0.4750 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 510us/sample - loss: 0.4732 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 787us/sample - loss: 0.4709 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 579us/sample - loss: 0.4692 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1332fc890>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45524424],\n",
       "       [0.61751765],\n",
       "       [0.71250975],\n",
       "       [0.3513887 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m.\u001b[m\u001b[m                  01_neuron.ipynb    04_mnist.ipynb     model.h5\r\n",
      "\u001b[36m..\u001b[m\u001b[m                 02_or_gate.ipynb   basic_model.json\r\n",
      "\u001b[36m.ipynb_checkpoints\u001b[m\u001b[m 03-xor-keras.ipynb basic_weights.h5\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.45524424],\n",
       "       [0.61751765],\n",
       "       [0.71250975],\n",
       "       [0.3513887 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model.\n",
    "model.save('model.h5')\n",
    "\n",
    "!ls -a \n",
    "\n",
    "# Recreate the exact same model purely from the file.\n",
    "new_model = tf.keras.models.load_model('model.h5')\n",
    "new_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://blog.thoughtram.io/machine-learning/2016/11/02/understanding-XOR-with-keras-and-tensorlow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

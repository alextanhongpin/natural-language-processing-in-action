{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclusive OR with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is required, else the results of the model training will differ vastly.\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[0, 0],\n",
    "                    [0, 1],\n",
    "                    [1, 0],\n",
    "                    [1, 1]])\n",
    "\n",
    "y_train = np.array([[0],\n",
    "                    [1],\n",
    "                    [1],\n",
    "                    [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "# The fully connected hidden layer will have 100 neurons.\n",
    "    num_neurons = 10\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(num_neurons, activation='relu', input_dim=2),\n",
    "        # The output layer has one neuron to output a single binary classification value (0 or 1).\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    sgd = SGD(0.1)\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Alternatively, we can use add each layer independently.\n",
    "# model.add(Dense(num_neurons, activation='relu', input_dim=2))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "# Overview of the network parameter and number of weights at each stage.\n",
    "# 10 neurons, each with two weights (one for each value in the input vector), \n",
    "# and one weight for the bias gives you 30 weights to learn.\n",
    "# The output layer has a weight for each of the 10 neurons in the first layer \n",
    "# and one bias weight for a total of 11 in that layer.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       ],\n",
       "       [0.28757626],\n",
       "       [0.5413843 ],\n",
       "       [0.25403112]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1221 14:46:44.952793 4450168256 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 17ms/sample - loss: 0.7115 - accuracy: 0.7500\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 546us/sample - loss: 0.6995 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 394us/sample - loss: 0.6887 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.6798 - accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.6726 - accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.6659 - accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6597 - accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 607us/sample - loss: 0.6542 - accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 515us/sample - loss: 0.6489 - accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 560us/sample - loss: 0.6439 - accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6395 - accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 766us/sample - loss: 0.6359 - accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 535us/sample - loss: 0.6320 - accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 526us/sample - loss: 0.6283 - accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 619us/sample - loss: 0.6254 - accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 383us/sample - loss: 0.6218 - accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 706us/sample - loss: 0.6189 - accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 849us/sample - loss: 0.6155 - accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 723us/sample - loss: 0.6125 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 731us/sample - loss: 0.6095 - accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 903us/sample - loss: 0.6064 - accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 799us/sample - loss: 0.6039 - accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 529us/sample - loss: 0.6014 - accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 621us/sample - loss: 0.5995 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 654us/sample - loss: 0.5964 - accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5947 - accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 930us/sample - loss: 0.5920 - accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5903 - accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.5879 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 738us/sample - loss: 0.5859 - accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 609us/sample - loss: 0.5838 - accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.5816 - accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5797 - accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5770 - accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.5755 - accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5735 - accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5715 - accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5697 - accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 532us/sample - loss: 0.5678 - accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.5664 - accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.5646 - accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5625 - accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5616 - accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.5593 - accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 909us/sample - loss: 0.5573 - accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 520us/sample - loss: 0.5558 - accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 676us/sample - loss: 0.5551 - accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 655us/sample - loss: 0.5532 - accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 709us/sample - loss: 0.5513 - accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 477us/sample - loss: 0.5502 - accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 425us/sample - loss: 0.5484 - accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 612us/sample - loss: 0.5464 - accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 768us/sample - loss: 0.5450 - accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5440 - accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 790us/sample - loss: 0.5419 - accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5404 - accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 975us/sample - loss: 0.5382 - accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.5377 - accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 719us/sample - loss: 0.5356 - accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5339 - accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.5327 - accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 654us/sample - loss: 0.5307 - accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 962us/sample - loss: 0.5295 - accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5273 - accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 416us/sample - loss: 0.5257 - accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 454us/sample - loss: 0.5250 - accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.5222 - accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 478us/sample - loss: 0.5208 - accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 692us/sample - loss: 0.5195 - accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 674us/sample - loss: 0.5179 - accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 703us/sample - loss: 0.5163 - accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 868us/sample - loss: 0.5141 - accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 522us/sample - loss: 0.5130 - accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 936us/sample - loss: 0.5113 - accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 767us/sample - loss: 0.5095 - accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 478us/sample - loss: 0.5077 - accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 648us/sample - loss: 0.5057 - accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 795us/sample - loss: 0.5046 - accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 974us/sample - loss: 0.5035 - accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 381us/sample - loss: 0.5017 - accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 759us/sample - loss: 0.5005 - accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 484us/sample - loss: 0.4996 - accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 558us/sample - loss: 0.4985 - accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 839us/sample - loss: 0.4965 - accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 344us/sample - loss: 0.4949 - accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 588us/sample - loss: 0.4945 - accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 519us/sample - loss: 0.4932 - accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 802us/sample - loss: 0.4915 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 371us/sample - loss: 0.4901 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 503us/sample - loss: 0.4888 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 646us/sample - loss: 0.4879 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 573us/sample - loss: 0.4870 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 466us/sample - loss: 0.4854 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 621us/sample - loss: 0.4838 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 535us/sample - loss: 0.4832 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 578us/sample - loss: 0.4819 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.4801 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 861us/sample - loss: 0.4794 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 650us/sample - loss: 0.4777 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.4772 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x127530b10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49407762],\n",
       "       [0.5063816 ],\n",
       "       [0.79505247],\n",
       "       [0.26788902]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m.\u001b[m\u001b[m                  01_neuron.ipynb    04_mnist.ipynb     model.h5\r\n",
      "\u001b[36m..\u001b[m\u001b[m                 02_or_gate.ipynb   basic_model.json\r\n",
      "\u001b[36m.ipynb_checkpoints\u001b[m\u001b[m 03-xor-keras.ipynb basic_weights.h5\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49407762],\n",
       "       [0.5063816 ],\n",
       "       [0.79505247],\n",
       "       [0.26788902]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model.\n",
    "model.save('model.h5')\n",
    "\n",
    "!ls -a \n",
    "\n",
    "# Recreate the exact same model purely from the file.\n",
    "new_model = tf.keras.models.load_model('model.h5')\n",
    "new_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://blog.thoughtram.io/machine-learning/2016/11/02/understanding-XOR-with-keras-and-tensorlow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
